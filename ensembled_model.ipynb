{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input shape and number of classes\n",
    "input_shape = (256, 256, 3)  # New input size\n",
    "num_classes = 1  # Binary classification (attentive vs. distracted)\n",
    "\n",
    "# Function to build a model\n",
    "def build_model(base_model, input_shape):\n",
    "    base_model = base_model(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False #Freezing base layers\n",
    "        \n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(num_classes, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "# Load pre-trained models\n",
    "vgg16_model = build_model(VGG16, input_shape)\n",
    "resnet50_model = build_model(ResNet50, input_shape)\n",
    "inceptionv3_model = build_model(InceptionV3, input_shape)\n",
    "\n",
    "# Compile models\n",
    "vgg16_model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "resnet50_model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "inceptionv3_model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202 images belonging to 2 classes.\n",
      "Found 50 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1]\n",
    "    rotation_range=40,  # Randomly rotate images\n",
    "    width_shift_range=0.2,  # Randomly shift images horizontally\n",
    "    height_shift_range=0.2,  # Randomly shift images vertically\n",
    "    shear_range=0.2,  # Shear transformations\n",
    "    zoom_range=0.2,  # Randomly zoom images\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    fill_mode='nearest',  # Fill missing pixels after transformations\n",
    "    validation_split=0.2  # Split 20% of the data for validation\n",
    ")\n",
    "\n",
    "# Load training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'Collected_Dataset',  # Path to dataset\n",
    "    target_size=input_shape[:2],  # Resize images to (256, 256)\n",
    "    batch_size=16,\n",
    "    class_mode='binary',\n",
    "    subset='training',  # Use the training subset\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'Collected_Dataset',  # Path to your dataset\n",
    "    target_size=input_shape[:2],  # Resize images to (256, 256)\n",
    "    batch_size=16,\n",
    "    class_mode='binary',\n",
    "    subset='validation',  # Use the validation subset\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning VGG16...\n",
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 0.5604 - loss: 0.6980 - val_accuracy: 0.5200 - val_loss: 0.7118\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.5742 - loss: 0.7435 - val_accuracy: 0.5000 - val_loss: 0.7016\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.5958 - loss: 0.6653 - val_accuracy: 0.4800 - val_loss: 0.7139\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.6208 - loss: 0.6294 - val_accuracy: 0.4400 - val_loss: 0.7278\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - accuracy: 0.6439 - loss: 0.6195 - val_accuracy: 0.4400 - val_loss: 0.7342\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.5861 - loss: 0.7229 - val_accuracy: 0.5400 - val_loss: 0.6900\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.6403 - loss: 0.6523 - val_accuracy: 0.5600 - val_loss: 0.6975\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - accuracy: 0.6755 - loss: 0.6299 - val_accuracy: 0.5400 - val_loss: 0.7241\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - accuracy: 0.6823 - loss: 0.5998 - val_accuracy: 0.4000 - val_loss: 0.7465\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.5685 - loss: 0.6664 - val_accuracy: 0.4600 - val_loss: 0.7493\n",
      "Fine-tuning ResNet50...\n",
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.4102 - loss: 0.7491 - val_accuracy: 0.5200 - val_loss: 0.6952\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.4376 - loss: 0.7064 - val_accuracy: 0.4600 - val_loss: 0.6932\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.5088 - loss: 0.6935 - val_accuracy: 0.5200 - val_loss: 0.7043\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.4937 - loss: 0.7024 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.4565 - loss: 0.6932 - val_accuracy: 0.4800 - val_loss: 0.6932\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.4752 - loss: 0.6932 - val_accuracy: 0.4800 - val_loss: 0.6932\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.4539 - loss: 0.6932 - val_accuracy: 0.5200 - val_loss: 0.6920\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.5532 - loss: 0.7055 - val_accuracy: 0.5200 - val_loss: 0.6931\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.4790 - loss: 0.6954 - val_accuracy: 0.5200 - val_loss: 0.6926\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.4587 - loss: 0.6955 - val_accuracy: 0.5200 - val_loss: 0.6931\n",
      "Fine-tuning InceptionV3...\n",
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.6360 - loss: 0.5984 - val_accuracy: 0.4600 - val_loss: 0.7009\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.6027 - loss: 0.6597 - val_accuracy: 0.5000 - val_loss: 0.7229\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.6374 - loss: 0.6516 - val_accuracy: 0.5600 - val_loss: 0.7038\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.6808 - loss: 0.6069 - val_accuracy: 0.4800 - val_loss: 0.7505\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.6255 - loss: 0.6064 - val_accuracy: 0.4800 - val_loss: 0.7366\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.6512 - loss: 0.5980 - val_accuracy: 0.5200 - val_loss: 0.6998\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7156 - loss: 0.5995 - val_accuracy: 0.5000 - val_loss: 0.7812\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.6491 - loss: 0.6087 - val_accuracy: 0.4400 - val_loss: 0.8188\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7202 - loss: 0.5480 - val_accuracy: 0.4600 - val_loss: 0.7358\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7066 - loss: 0.5553 - val_accuracy: 0.4800 - val_loss: 0.8551\n",
      "Generating predictions...\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step\n",
      "Evaluating ensemble...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Focused       0.52      0.58      0.55        26\n",
      "  Distracted       0.48      0.42      0.44        24\n",
      "\n",
      "    accuracy                           0.50        50\n",
      "   macro avg       0.50      0.50      0.49        50\n",
      "weighted avg       0.50      0.50      0.50        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Common early stopping\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Fine-tune models\n",
    "\n",
    "# === VGG16 ===\n",
    "checkpoint_vgg = ModelCheckpoint('best_model_vgg16.keras', monitor='val_accuracy', save_best_only=True)\n",
    "print(\"Fine-tuning VGG16...\")\n",
    "vgg16_model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[earlystop, checkpoint_vgg]\n",
    ")\n",
    "\n",
    "# === ResNet50 ===\n",
    "checkpoint_resnet = ModelCheckpoint('best_model_resnet50.keras', monitor='val_accuracy', save_best_only=True)\n",
    "print(\"Fine-tuning ResNet50...\")\n",
    "resnet50_model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[earlystop, checkpoint_resnet]\n",
    ")\n",
    "\n",
    "# === InceptionV3 ===\n",
    "checkpoint_inception = ModelCheckpoint('best_model_inceptionv3.keras', monitor='val_accuracy', save_best_only=True)\n",
    "print(\"Fine-tuning InceptionV3...\")\n",
    "inceptionv3_model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[earlystop, checkpoint_inception]\n",
    ")\n",
    "\n",
    "\n",
    "# Generate predictions on the validation set\n",
    "print(\"Generating predictions...\")\n",
    "vgg16_preds = vgg16_model.predict(validation_generator)\n",
    "resnet50_preds = resnet50_model.predict(validation_generator)\n",
    "inceptionv3_preds = inceptionv3_model.predict(validation_generator)\n",
    "\n",
    "# Convert predictions to binary (0 or 1)\n",
    "vgg16_preds = [1 if pred > 0.5 else 0 for pred in vgg16_preds]\n",
    "resnet50_preds = [1 if pred > 0.5 else 0 for pred in resnet50_preds]\n",
    "inceptionv3_preds = [1 if pred > 0.5 else 0 for pred in inceptionv3_preds]\n",
    "\n",
    "# Combine predictions using majority voting\n",
    "ensemble_preds = []\n",
    "for vgg_pred, resnet_pred, inception_pred in zip(vgg16_preds, resnet50_preds, inceptionv3_preds):\n",
    "    votes = [vgg_pred, resnet_pred, inception_pred]\n",
    "    majority_vote = max(set(votes), key=votes.count)\n",
    "    ensemble_preds.append(majority_vote)\n",
    "\n",
    "# Evaluate the ensemble\n",
    "print(\"Evaluating ensemble...\")\n",
    "report = classification_report(validation_generator.classes, ensemble_preds, target_names=['Focused', 'Distracted'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save VGG16 model\n",
    "vgg16_model.save('vgg16_model.keras')\n",
    "\n",
    "# Save ResNet50 model\n",
    "resnet50_model.save('resnet50_model.keras')\n",
    "\n",
    "# Save InceptionV3 model\n",
    "inceptionv3_model.save('inceptionv3_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
